{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIMIT Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and minibatch TIMIT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet   \n",
    "using Compat,GZip\n",
    "using Images\n",
    "using HDF5, JLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atype = KnetArray{Float32}\n",
    "Ctype = Array{Float32}\n",
    "gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileToRead = \"timitdata.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrn = h5read(fileToRead,\"labelsTrn\")\n",
    "summary(ytrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytst = h5read(fileToRead,\"labelsTst\")\n",
    "summary(ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrn = h5read(fileToRead,\"imagesTrn\")\n",
    "summary(xtrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtst = h5read(fileToRead,\"imagesTst\")\n",
    "summary(xtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrn = reshape(xtrn, (40,14,1,121583))\n",
    "xtst = reshape(xtst, (40,14,1,44125))\n",
    "map(summary,(xtrn,xtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muX = mean(xtrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrn = xtrn.-muX\n",
    "xtst = xtst.-muX;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(xtrn), mean(xtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quickview(x,i)=colorview(Gray,permutedims(x[:,:,1,i],(2,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcat([quickview(xtrn,i) for i=1:10]...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrn[1:10]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcat([quickview(xtst,i) for i=1:10]...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytst[1:10]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrn = convert(Atype, xtrn);\n",
    "xtst = convert(Atype, xtst);\n",
    "map(summary,(xtrn,xtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb = 40\n",
    "dtst = minibatch(xtst,ytst,Nb;xtype=Atype) # [ (x1,y1), (x2,y2), ... ] where xi,yi are minibatches of Nb\n",
    "dtrn = minibatch(xtrn,ytrn,Nb;xtype=Atype) # [ (x1,y1), (x2,y2), ... ] where xi,yi are minibatches of Nb\n",
    "length(dtrn),length(dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y) = first(dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knetgc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MNIST using MLP with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "zeroone(w,data,predict) = 1 - accuracy(w,data,predict)\n",
    "loss(w,data,predict) = mean(loss(w,x,y,predict) for (x,y) in data)\n",
    "loss(w,x,y,predict; o...) = nll(predict(w,x;o...),y)\n",
    "lossgrad = grad(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mlpdrop(w,x; pdrop=(0,0))\n",
    "    x = mat(x)\n",
    "    x = dropout(x,pdrop[1])\n",
    "    for i=1:2:length(w)-2\n",
    "        x = relu.(w[i]*x .+ w[i+1])\n",
    "        x = dropout(x,pdrop[2])\n",
    "    end\n",
    "    return w[end-1]*x .+ w[end]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function winit(h...; std=0.01, x=40*14, y=45, atype=gpu()>=0 ? KnetArray{Float32} : Array{Float32})\n",
    "    h = [x, h..., y]   # use winit(h1,h2,...,hn) for n hidden layer mlp\n",
    "    w = Any[]\n",
    "    for i=1:length(h)-1\n",
    "        push!(w, std*randn(h[i+1],h[i]))\n",
    "        push!(w, zeros(h[i+1],1))\n",
    "    end\n",
    "    map(atype, w)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts=winit(1024,256,64) # gives weights and biases for an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(wts,x,y,mlpdrop)  # Average loss for a single (x,y) minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(wts,dtst,mlpdrop)  # Average loss for the whole test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model(w) with SGD and return a list containing w for every epoch\n",
    "function train(w,data,predict; epochs=10,lr=0.15,o...)\n",
    "    weights = Any[deepcopy(w)]\n",
    "    #opts = map(x->Sgd(lr=lr), w)#sgd with default learning rate\n",
    "    opts = map(x->Adam(), w)\n",
    "    for epoch in 1:epochs\n",
    "        for (x,y) in data\n",
    "            g = lossgrad(w,x,y,predict;o...)\n",
    "            update!(w,g,opts)  # w[i] = w[i] - lr * g[i]\n",
    "        end\n",
    "        push!(weights,deepcopy(w))\n",
    "    end\n",
    "    return weights\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srand(1)\n",
    "@time trn1=train(wts,dtrn,mlpdrop;epochs=15,lr=0.15,pdrop=(0.2,0));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time trnloss1 = [ loss(w,dtrn,mlpdrop) for w in trn1 ]\n",
    "@time tstloss1 = [ loss(w,dtst,mlpdrop) for w in trn1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time trnerr1 = [ zeroone(w,dtrn,mlpdrop) for w in trn1 ]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time tsterr1 = [ zeroone(w,dtst,mlpdrop) for w in trn1 ]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum(trnerr1),minimum(tsterr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = trn1 = trnloss1 = tstloss1 = trnerr1 = tsterr1 = nothing; knetgc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MNIST using a Baseline CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function convnet(w,x; activation=(relu,relu), pdrop=(0,0,0))    # pdrop[1]:input, pdrop[2]:conv, pdrop[3]:fc\n",
    "    for i=1:2:length(w)\n",
    "        if ndims(w[i]) == 4     # convolutional layer\n",
    "            x = dropout(x, pdrop[i==1?1:2])\n",
    "            x = conv4(w[i], x, padding=1) .+ w[i+1]\n",
    "            x = pool(activation[1].(x))\n",
    "        elseif ndims(w[i]) == 2 # fully connected layer\n",
    "            if i == length(w)-1; x = dropout(x, pdrop[i==1?1:3]); end\n",
    "            # x = dropout(x, pdrop[i==1?1:3])  Hinton used dropout only in the final FC layer!\n",
    "            x = w[i]*mat(x) .+ w[i+1]\n",
    "            if i < length(w)-1; x = activation[2].(x); end\n",
    "        else\n",
    "            error(\"Unknown layer type: $(size(w[i]))\")\n",
    "        end\n",
    "    end\n",
    "    return x\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initialization for multiple layers\n",
    "# h[i] is an integer for a fully connected layer, a triple of integers for convolution filters\n",
    "# Output is an array [w0,b0,w1,b1,...,wn,bn] where wi,bi is the weight matrix/tensor and bias vector for the i'th layer\n",
    "function cinit(h...)  # use cinit(x,h1,h2,...,hn,y) for n hidden layer model\n",
    "    w = Any[]\n",
    "    x = h[1]\n",
    "    for i=2:length(h)\n",
    "        if isa(h[i],Tuple)\n",
    "            (x1,x2,cx) = x\n",
    "            (w1,w2,cy) = h[i]\n",
    "            push!(w, xavier(w1,w2,cx,cy))\n",
    "            push!(w, zeros(1,1,cy,1))\n",
    "            x = (div(x1-w1+1+2,2),div(x2-w2+1+2,2),cy)\n",
    "        elseif isa(h[i],Integer)\n",
    "            push!(w, xavier(h[i],prod(x)))\n",
    "            push!(w, zeros(h[i],1))\n",
    "            x = h[i]\n",
    "        else\n",
    "            error(\"Unknown layer type: $(h[i])\")\n",
    "        end\n",
    "    end\n",
    "    map(Atype, w)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnbase=cinit((40,14,1), (5,3,256), (5,3,256), (5,3,128), 328, 192, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y) = first(dtst)\n",
    "loss(cnnbase,x,y,convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srand(1)\n",
    "@time weights=train(cnnbase,dtrn,convnet;epochs=10,lr=0.15,pdrop=(0,0,0.30))\n",
    "#@time trnloss = [ loss(w,dtrn,convnet) for w in weights ]\n",
    "#@time tstloss = [ loss(w,dtst,convnet) for w in weights ]\n",
    "@time trnerr = [ zeroone(w,dtrn,convnet) for w in weights ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time tsterr = [ zeroone(w,dtst,convnet) for w in weights ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum(trnerr),minimum(tsterr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnbase = weights = trnloss = tstloss = trnerr = tsterr = nothing; knetgc()\n",
    "# Knet.gpuinfo() # Knet.meminfo() # Knet.memdbg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Capsule Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atype, Ctype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nclass = 45  # number of classes\n",
    "Vprimes = 16  # number of primary capsules vertically stacked (along z-axis), focusing on the same segment of images\n",
    "Nax1primes = 12  # number of primary capsules along axis-1 (y-axis) of an image: Julia is column-major!\n",
    "Nax2primes = 3  # number of primary capsules along axis-2 (x-axis) of an image\n",
    "Nsegm = Nax1primes*Nax2primes  # number of segments per image: one primary capsule for each segment of each image\n",
    "Nprimes = Nsegm*Vprimes  # total number of primary capsule\n",
    "Dprime = 8  # dimension of a primary capsules\n",
    "Dsecond = 16 # dimension of a secondary (higher layer) capsule\n",
    "Nchannels = Vprimes*Dprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function winitdecoder(h...; x=Nclass*Dsecond, y=28*14) \n",
    "    h = [x, h..., y]   # use winit(h1,h2,...,hn) for n hidden layer mlp\n",
    "    w = Any[]\n",
    "    for i=1:length(h)-1\n",
    "        push!(w, xavier(h[i+1],h[i]))\n",
    "        push!(w, zeros(h[i+1],1))\n",
    "    end\n",
    "    return w\n",
    "    #map(Atype, w)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function wtsinit()\n",
    "    wts = Any[ xavier(9,5,1,Nchannels),  zeros(1,1,Nchannels,1),\n",
    "        xavier(9,5,Nchannels,Nchannels), zeros(1,1,Nchannels,1)]\n",
    "    # W = 0.1*randn(Dprime,Nprimes,Nclass,Dsecond) \n",
    "    W = xavier(Dprime,Nprimes,Nclass,Dsecond)\n",
    "    push!(wts,W)\n",
    "    # append!(wts, winitdecoder(512,1024))  # for reconstruction\n",
    "    wts = map(Atype, wts)\n",
    "\n",
    "    return wts\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function convLayer(w, x, strides=(1,2))\n",
    "    # dropouts =(0,0)\n",
    "    # paddings = (0,0)\n",
    "    # strides = (1,2)\n",
    "    for i=1:2:length(w)\n",
    "        # x = dropout(x, dropouts[i==1?1:2])\n",
    "        x = conv4(w[i], x, stride=strides[i==1?1:2]) .+ w[i+1]\n",
    "        x = relu.(x)\n",
    "    end\n",
    "    # print(summary(x))\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function softMax(X; axis=2) \n",
    "    X = X .- maximum(X, axis)\n",
    "    prob = exp.(X) ./ sum(exp.(X), axis)\n",
    "    return prob\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function safeNorm(s; axis=4, eps=1e-7)\n",
    "    sNorm2 = sum(abs2.(s),axis)\n",
    "    sNorm = sqrt.(sNorm2+eps)\n",
    "    return sNorm\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function squash(s; axis=4, eps=1e-7)    \n",
    "    sNorm2 = sum(abs2.(s),axis)\n",
    "    sNorm = sqrt.(sNorm2+eps)\n",
    "    #sNorm, sNorm2 = safeNorm(s,axis=axis)\n",
    "    sUnit = s ./ sNorm\n",
    "    sFactor = sNorm2./(sNorm2.+1)\n",
    "    V = sFactor.*sUnit\n",
    "    return V\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function maxidx(matrix)  # find index of maximums along axis-1 (columns)\n",
    "    M = size(matrix,1)\n",
    "    N = size(matrix,2)  \n",
    "    idxes = zeros(Int8,N)\n",
    "    maxes = maximum(matrix, 1)\n",
    "\n",
    "    for j=1:N\n",
    "        for i=1:M\n",
    "            if maxes[j]==matrix[i,j]\n",
    "            idxes[j] = i\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return idxes\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y) = first(dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map(summary,first(dtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1hot(y) = convert(Ctype, sparse(convert(Vector{Int},y),1:length(y),one(eltype(y)),Nclass,length(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function decode(w,vtodeco)\n",
    "    #x = mat(x)\n",
    "    for i=1:2:length(w)-2\n",
    "        vtodeco = relu.(w[i]*vtodeco .+ w[i+1])\n",
    "    end\n",
    "    return sigm.(w[end-1]*vtodeco .+ w[end])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mask(v, y1ht)\n",
    "    vmasked = permutedims(y1ht.*v , (1,3,2))\n",
    "    vtodecode = reshape(vmasked,(Dsecond*Nclass,Nb))\n",
    "    return vtodecode\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function capsnet(w, x)\n",
    "    con = convLayer(w[1:4],x)\n",
    "    pri = reshape(con,(Nax1primes,Nax2primes,Dprime,Vprimes,Nb))\n",
    "    pri = permutedims(pri,(1,2,4,3,5))\n",
    "    pri = reshape(pri,(Nprimes,Dprime,Nb))\n",
    "    pri = permutedims(pri,(2,1,3))\n",
    "    pri = squash(pri, axis=1)  # along the contents of primary capsules\n",
    "    pri = reshape(pri,(Dprime,Nprimes,1,1,Nb))\n",
    "\n",
    "    UHat = convert(Atype, ones(Dprime,Nprimes,Nclass,Dsecond,Nb))\n",
    "    W = w[5].*UHat  # achieved tiling to higher dimensions!\n",
    "    \n",
    "    UHat = pri.*W\n",
    "    UHat = sum(UHat,1)  # achieved affine transformations without matmul!\n",
    "    UHat = permutedims(reshape(UHat,(Nprimes,Nclass,Dsecond,Nb)), (1,2,4,3))\n",
    "    \n",
    "    B = convert(Atype, zeros(Nprimes,Nclass,Nb))     \n",
    "    \n",
    "    C = softMax(B, axis=2) # C is normalized along 2nd dim (classes)\n",
    "    S = C.*UHat\n",
    "    s = sum(S,1)\n",
    "    v = squash(s)\n",
    "    \n",
    "    maxiter = 1\n",
    "    for r=1:maxiter\n",
    "        A = v.* UHat\n",
    "        Agreement = sum(A,4)\n",
    "        Agreement = reshape(Agreement, (Nprimes,Nclass,Nb))\n",
    "        B = B .+ Agreement\n",
    "        \n",
    "        C = softMax(B, axis=2)\n",
    "        S = C.*UHat\n",
    "        s = sum(S,1)\n",
    "        v = squash(s)\n",
    "    end    \n",
    "    \n",
    "    yprob = safeNorm(v)\n",
    "    yprob = reshape(yprob, (Nclass,Nb))\n",
    "    v = reshape(v, (Nclass,Nb,Dsecond));\n",
    "\n",
    "    return yprob, v\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda = 0.5\n",
    "rloss = 0.0005;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function lossCaps(w, x, y, predict; training = true)\n",
    "    yp, v = predict(w, x)\n",
    "    yp = convert(Ctype,yp)\n",
    "    nb = size(x,4)\n",
    "    y1hot = conv1hot(y)\n",
    "    lossmargin = sum((abs2.(relu.(m_plus.-yp)).*y1hot)+lambda.*(abs2.(relu.(yp.-m_minus))).*(1-y1hot))\n",
    "    # xmat = mat(x)\n",
    "    # if training\n",
    "    #     vmasked = mask(v, y1hot)\n",
    "    # else\n",
    "    #     yp1hot = conv1hot(maxidx(yp))\n",
    "    #     vmasked = mask(v, yp1hot)\n",
    "    # end\n",
    "    # xr = decode(w[6:11], vmasked)\n",
    "    # lossreconstruction = sum(abs2.(xmat.-xr)) \n",
    "    return lossmargin # + rloss*lossreconstruction\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function accurate(ygold, yhat)\n",
    "    correct = 0.0\n",
    "    Nb = length(ygold)\n",
    "    for i=1:Nb\n",
    "        correct += (ygold[i]==yhat[i]) ? 1.0 : 0.0\n",
    "    end\n",
    "    return correct / Nb\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function accurate(w,x,y,predict)\n",
    "    yprb, v = predict(w,x)\n",
    "    yprb = convert(Ctype,yprb)\n",
    "    yhat = maxidx(yprb)\n",
    "    return accurate(y, yhat)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions for Capsnet\n",
    "pererror(w,data,predict) = 1 - accurate(w,data,predict)\n",
    "accurate(w,data,predict) = mean(accurate(w,x,y,predict) for (x,y) in data)\n",
    "lossCaps(w,data,predict; o...) = mean(lossCaps(w,x,y,predict;o...) for (x,y) in data)\n",
    "lossCapsgrad = grad(lossCaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function trainCaps(w,data,predict; epochs=2,lr=0.15,o...)\n",
    "    weights = Any[deepcopy(w)]\n",
    "    #opts = map(x->Sgd(lr=lr), w)#sgd with default learning rate\n",
    "    opts = map(x->Adam(), w)\n",
    "    for epoch in 1:epochs\n",
    "        for (x,y) in data\n",
    "            g = lossCapsgrad(w,x,y,predict;o...)\n",
    "            update!(w,g,opts)  # w[i] = w[i] - lr * g[i]\n",
    "        end\n",
    "        push!(weights,deepcopy(w))\n",
    "    end\n",
    "    return weights\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srand(1)\n",
    "wtscap = wtsinit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprb1, v1 = capsnet(wtscap,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossCaps(wtscap,x,y,capsnet;training=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accurate(wtscap,x,y,capsnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wtscap = wnext  # if read from results file\n",
    "@time weights = trainCaps(wtscap,dtrn,capsnet; epochs=5,lr=0.15)  # obviously increase epochs as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time trnerr = [ pererror(w,dtrn,capsnet) for w in weights[2:end] ]  # [2:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time tsterr = [ pererror(w,dtst,capsnet) for w in weights[2:end] ]  # [2:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnext = convert(Array{Ctype},weights[end])  # before writing to results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### OVERWRITES\n",
    "jldopen(\"timitresults.jld\", \"w\") do file\n",
    "    write(file, \"wnext\", wnext)  \n",
    "    write(file, \"trnerr\", trnerr)  \n",
    "    write(file, \"tsterr\", tsterr)    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = load(\"timitresults.jld\")  # to read previously stored results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsterr = D[\"tsterr\"]  # D is a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnext = convert(Array{Atype},D[\"wnext\"])  # after reading from results file, use to initialize wtscap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "plotly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plots.plot([trnerr tsterr],ylim=(0,1.0),linewidth=3,labels=[:Train_Error :Test_Error],xlabel=\"Epochs\", ylabel=\"TIMIT Errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
